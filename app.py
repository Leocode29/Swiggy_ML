import streamlit as st
import pandas as pd
import pickle
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

# Page Configuration
st.set_page_config(page_title="Swiggy Restaurant Recommender", layout="wide")

# Title and Description
st.title("üçΩÔ∏è Swiggy Restaurant Recommendation System")
st.markdown("Discover the best restaurants based on City, Cuisine, Rating, and Cost.")
st.markdown("---")

# 1. Load Data and Artifacts (Cached to save memory)
@st.cache_data
def load_data():
    try:
        # Load the files generated by preprocessing.py
        cleaned_data = pd.read_csv('cleaned_data.csv')
        encoded_data = pd.read_csv('encoded_data.csv')
        
        with open('encoder.pkl', 'rb') as f:
            encoder = pickle.load(f)
            
        return cleaned_data, encoded_data, encoder
    except FileNotFoundError:
        return None, None, None

cleaned_df, encoded_df, encoder = load_data()

# 2. Safety Check: Ensure data is loaded before running app
if cleaned_df is not None and encoded_df is not None and encoder is not None:
    
    # --- SIDEBAR: User Inputs ---
    st.sidebar.header("üîç Filter Preferences")
    
    # City Selection
    unique_cities = cleaned_df['city'].unique()
    selected_city = st.sidebar.selectbox("Select City", unique_cities)
    
    # Cuisine Selection (Filtered by City)
    # We only show cuisines available in the selected city
    city_filtered_df = cleaned_df[cleaned_df['city'] == selected_city]
    unique_cuisines = city_filtered_df['cuisine'].unique()
    selected_cuisine = st.sidebar.selectbox("Select Cuisine", unique_cuisines)
    
    # Rating and Cost Sliders
    min_rating = st.sidebar.slider("Minimum Rating", 0.0, 5.0, 3.5, 0.1)
    max_cost = st.sidebar.slider("Maximum Cost (‚Çπ)", 50, 2000, 500, 50)

    # --- RECOMMENDATION ENGINE ---
    if st.sidebar.button("Show Recommendations"):
        
        try:
            # Step A: Filter Data *Before* Processing (Fixes OOM Crash)
            # 1. Get the indices (row numbers) of restaurants in the selected city
            city_indices = cleaned_df[cleaned_df['city'] == selected_city].index
            
            # 2. Slice the encoded data to keep ONLY that city's rows
            # This reduces memory usage significantly
            filtered_encoded_df = encoded_df.iloc[city_indices]
            
            # Step B: Prepare User Input Vector
            input_data = pd.DataFrame({
                'city': [selected_city],
                'cuisine': [selected_cuisine]
            })
            
            # Transform categorical input
            input_encoded = encoder.transform(input_data)
            
            # Combine with numerical inputs [rating, cost]
            user_vector = np.concatenate([[ [min_rating, max_cost] ], [input_encoded[0]]], axis=1)
            
            # Step C: Compute Cosine Similarity
            # Now we only compare against the filtered subset, not the whole file
            similarity_scores = cosine_similarity(user_vector, filtered_encoded_df)
            
            # Step D: Get Recommendations
            # Create a copy of the city-specific dataframe to display results
            results_df = city_filtered_df.copy()
            results_df['similarity_score'] = similarity_scores[0]
            
            # Sort by highest score
            recommendations = results_df.sort_values(by='similarity_score', ascending=False)
            
            # --- OUTPUT DISPLAY ---
            st.subheader(f"Top Recommendations in {selected_city}")
            
            # Display top 5 results
            top_results = recommendations.head(5)
            
            if not top_results.empty:
                cols = st.columns(3) 
                for idx, (index, row) in enumerate(top_results.iterrows()):
                    with cols[idx % 3]: 
                        st.markdown(f"### {row['name']}")
                        st.write(f"**Cuisine:** {row['cuisine']}")
                        st.write(f"‚≠ê **Rating:** {row['rating']} | üí∞ **Cost:** ‚Çπ{row['cost']}")
                        st.write(f"üìç **Address:** {row['address']}")
                        if 'link' in row and pd.notna(row['link']):
                            st.markdown(f"[üîó View on Swiggy]({row['link']})")
                        st.divider()
            else:
                st.warning("No exact matches found. Try widening your price or rating filters.")
                
        except Exception as e:
            st.error(f"An error occurred during calculation: {e}")

else:
    # Fallback if files are missing
    st.error("‚ö†Ô∏è Data files not found!")
    st.info("Please make sure 'cleaned_data.csv', 'encoded_data.csv', and 'encoder.pkl' are in the same folder.")